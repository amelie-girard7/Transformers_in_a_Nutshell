{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEBVTT\n",
      "\n",
      "1\n",
      "00:00:07.310 --> 00:00:12.930\n",
      "Massimo Piccardi: A transformer is a network consisting of 2 sub-networks.\n",
      "\n",
      "2\n",
      "00:00:14.920 --> 00:00:16.490\n",
      "Massimo Piccardi: an encoder\n",
      "\n",
      "3\n",
      "00:00:18.890 --> 00:00:21.480\n",
      "Massimo Piccardi: and a decoder\n",
      "\n",
      "4\n",
      "00:00:27.300 --> 00:00:30.700\n",
      "Massimo Piccardi: the 2 networks are connected somehow.\n",
      "\n",
      "5\n",
      "00:00:30.710 --> 00:00:33.990\n",
      "Massimo Piccardi: and the main usage is as follows.\n",
      "\n",
      "6\n",
      "00:00:35.320 --> 00:00:43.520\n",
      "Massimo Piccardi: there is a text in input to the e\n"
     ]
    }
   ],
   "source": [
    "# First, I'll open and read the content of the file to understand its structure and the task at hand.\n",
    "file_path = './transcript.txt'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    file_content = file.read()\n",
    "\n",
    "# Displaying the first few lines of the file for a better understanding\n",
    "print(file_content[:500])  # Display first 500 characters to get a sense of the content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEBVTT\n",
      "\n",
      "1\n",
      "\n",
      "A transformer is a network consisting of 2 sub-networks.\n",
      "\n",
      "2\n",
      "\n",
      "an encoder\n",
      "\n",
      "3\n",
      "\n",
      "and a decoder\n",
      "\n",
      "4\n",
      "\n",
      "the 2 networks are connected somehow.\n",
      "\n",
      "5\n",
      "\n",
      "and the main usage is as follows.\n",
      "\n",
      "6\n",
      "\n",
      "there is a text in input to the encoder. The text is\n",
      "\n",
      "7\n",
      "\n",
      "like the\n",
      "\n",
      "8\n",
      "\n",
      "cat\n",
      "\n",
      "9\n",
      "\n",
      "is\n",
      "\n",
      "10\n",
      "\n",
      "on.\n",
      "\n",
      "11\n",
      "\n",
      "This text gets split into individual words\n",
      "\n",
      "12\n",
      "\n",
      "which are more commonly called and more properly called tokens.\n",
      "\n",
      "13\n",
      "\n",
      "This action, or splitting the original text into tokens, is called tokenization\n",
      "\n",
      "14\n",
      "\n",
      "and follows a spec\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to remove the timestamps and the specific name \"Massimo Piccardi\" from the text\n",
    "def clean_text(text):\n",
    "    # Removing timestamps: Pattern looks like '00:00:07.310 --> 00:00:12.930'\n",
    "    text = re.sub(r'\\d{2}:\\d{2}:\\d{2}\\.\\d{3} --> \\d{2}:\\d{2}:\\d{2}\\.\\d{3}', '', text)\n",
    "    # Removing lines with \"Massimo Piccardi\"\n",
    "    text = re.sub(r'Massimo Piccardi: ', '', text)\n",
    "    return text\n",
    "\n",
    "# Applying the cleaning function to the file content\n",
    "cleaned_content = clean_text(file_content)\n",
    "\n",
    "# Displaying the first 500 characters of the cleaned content for verification\n",
    "print(cleaned_content[:500])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEBVTT\n",
      "\n",
      "A transformer is a network consisting of 2 sub-networks.\n",
      "\n",
      "an encoder\n",
      "\n",
      "and a decoder\n",
      "\n",
      "the 2 networks are connected somehow.\n",
      "\n",
      "and the main usage is as follows.\n",
      "\n",
      "there is a text in input to the encoder. The text is\n",
      "\n",
      "like the\n",
      "\n",
      "cat\n",
      "\n",
      "is\n",
      "\n",
      "on.\n",
      "\n",
      "This text gets split into individual words\n",
      "\n",
      "which are more commonly called and more properly called tokens.\n",
      "\n",
      "This action, or splitting the original text into tokens, is called tokenization\n",
      "\n",
      "and follows a specific algorithm specific for the model or specif\n"
     ]
    }
   ],
   "source": [
    "# Modified function to remove line numbers, accounting for possible variations in line endings or invisible characters\n",
    "def remove_line_numbers_modified(text):\n",
    "    # The modified pattern aims to be more robust against different line ending characters or extra spaces\n",
    "    return re.sub(r'^\\d+\\s*\\r?\\n', '', text, flags=re.MULTILINE)\n",
    "\n",
    "# Applying the modified function to remove line numbers from the original cleaned content\n",
    "cleaned_content_no_line_numbers_modified = remove_line_numbers_modified(cleaned_content)\n",
    "\n",
    "# Displaying the first 500 characters of the updated content for verification\n",
    "print(cleaned_content_no_line_numbers_modified[:500])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEBVTT\n",
      "A transformer is a network consisting of 2 sub-networks.\n",
      "an encoder\n",
      "and a decoder\n",
      "the 2 networks are connected somehow.\n",
      "and the main usage is as follows.\n",
      "there is a text in input to the encoder. The text is\n",
      "like the\n",
      "cat\n",
      "is\n",
      "on.\n",
      "This text gets split into individual words\n",
      "which are more commonly called and more properly called tokens.\n",
      "This action, or splitting the original text into tokens, is called tokenization\n",
      "and follows a specific algorithm specific for the model or specific for the lan\n"
     ]
    }
   ],
   "source": [
    "# Function to remove all empty lines from the text\n",
    "def remove_empty_lines(text):\n",
    "    # Removing empty lines: This can be done by filtering out lines that are empty or contain only whitespace\n",
    "    return '\\n'.join([line for line in text.splitlines() if line.strip()])\n",
    "\n",
    "# Applying the function to remove empty lines from the cleaned content\n",
    "merged_content = remove_empty_lines(cleaned_content_no_line_numbers)\n",
    "\n",
    "# Displaying the first 500 characters of the merged content for verification\n",
    "print(merged_content[:500])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./cleaned_transcript.txt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the cleaned content to a new file\n",
    "cleaned_file_path = './cleaned_transcript.txt'\n",
    "\n",
    "with open(cleaned_file_path, 'w') as file:\n",
    "    file.write(merged_content)\n",
    "\n",
    "cleaned_file_path\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
